{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krupaltisgaonkar/pytorch-ssd/blob/main/SSD_MobileNet_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485e85fd",
      "metadata": {
        "id": "485e85fd"
      },
      "source": [
        "# SSD MobileNet Training in PyTorch\n",
        "This notebook walks through the steps to train an SSD MobileNet model using PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make sure you are using a GPU"
      ],
      "metadata": {
        "id": "hmAtZACI5kzI"
      },
      "id": "hmAtZACI5kzI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under Runtime"
      ],
      "metadata": {
        "id": "EH_Nxz5J5jV-"
      },
      "id": "EH_Nxz5J5jV-"
    },
    {
      "cell_type": "markdown",
      "id": "2306b8aa",
      "metadata": {
        "id": "2306b8aa"
      },
      "source": [
        "## Install and Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f482d1",
      "metadata": {
        "id": "c3f482d1"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision pycocotools\n",
        "!pip install --upgrade protobuf\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82efdd21",
      "metadata": {
        "id": "82efdd21"
      },
      "source": [
        "## Upload Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f98f53",
      "metadata": {
        "id": "c0f98f53"
      },
      "source": [
        "Make sure your dataset is setup like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "├── images/\n",
        "│   ├── image1.png\n",
        "├── labels/\n",
        "│   ├── image1.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7673023b",
      "metadata": {
        "id": "7673023b"
      },
      "source": [
        "### Option 1: Use Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e3b56c7",
      "metadata": {
        "id": "4e3b56c7"
      },
      "source": [
        "It is expected that your dataset is zipped in google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183eb96b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "183eb96b",
        "outputId": "0e1dd0ec-bd35-466b-e097-b35cc724cba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted from Google Drive to: data/\n"
          ]
        }
      ],
      "source": [
        "drive_dataset_path = \"/content/drive/MyDrive/dataset/YOLO/dataset.zip\"  # Replace with your Google Drive dataset path\n",
        "if os.path.exists(drive_dataset_path):\n",
        "    with zipfile.ZipFile(drive_dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"data\")\n",
        "    print(f\"Dataset extracted from Google Drive to: data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97122984",
      "metadata": {
        "id": "97122984"
      },
      "source": [
        "### Option 2: Upload Manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242f3c2f",
      "metadata": {
        "id": "242f3c2f"
      },
      "outputs": [],
      "source": [
        "print(\"Upload your zipped dataset...\")\n",
        "uploaded = files.upload()\n",
        "# Extract the uploaded dataset\n",
        "if uploaded:\n",
        "    for filename in uploaded.keys():\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"data\")\n",
        "        print(f\"Dataset extracted to: data/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b43df9b",
      "metadata": {
        "id": "3b43df9b"
      },
      "source": [
        "## Resize Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "159ba39e",
      "metadata": {
        "id": "159ba39e"
      },
      "source": [
        "### Resize Images\n",
        "\n",
        "You will have to resize your images to 640 by 640 to ensure accuracy and faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96a7209",
      "metadata": {
        "id": "a96a7209"
      },
      "outputs": [],
      "source": [
        "def resize_images(input_dir, output_dir, new_size=(640, 640)):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            img_path = os.path.join(input_dir, filename)\n",
        "            img = Image.open(img_path)\n",
        "            img_resized = img.resize(new_size)\n",
        "            img_resized.save(os.path.join(output_dir, filename))\n",
        "    print(f\"Images resized and saved to {output_dir}.\")\n",
        "\n",
        "# Resize train and val images\n",
        "resize_images(\"data/images\", \"custom_dataset/images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "637dd924",
      "metadata": {
        "id": "637dd924"
      },
      "source": [
        "### Resize Labels\n",
        "\n",
        "You will have to resize your labels for your resized images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba1a0772",
      "metadata": {
        "id": "ba1a0772"
      },
      "outputs": [],
      "source": [
        "!wget -O /content/resize_labels.py https://raw.githubusercontent.com/krupaltisgaonkar/pytorch/refs/heads/main/scripts/resize_labels.py\n",
        "\n",
        "!python resize_labels.py --input_label_dir data/labels \\\n",
        "                 --input_image_dir data/images \\\n",
        "                 --output_label_dir custom_dataset/labels \\\n",
        "                 --new_size 640"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02be93ec",
      "metadata": {
        "id": "02be93ec"
      },
      "source": [
        "## Set Dataset Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5114b148",
      "metadata": {
        "id": "5114b148"
      },
      "outputs": [],
      "source": [
        "# Set dataset paths\n",
        "dataset_root = 'custom_dataset/'\n",
        "image_dir = f'{dataset_root}/images'\n",
        "label_dir = f'{dataset_root}/labels'\n",
        "classes_file = f'data/classes.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5771b5b1",
      "metadata": {
        "id": "5771b5b1"
      },
      "source": [
        "## Read Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c4e454",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66c4e454",
        "outputId": "c8d2c4ce-f76e-4cff-85da-994d5137a9d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['fish'], Total: 1\n"
          ]
        }
      ],
      "source": [
        "# Read class labels\n",
        "with open(classes_file, 'r') as f:\n",
        "    class_labels = [line.strip() for line in f.readlines()]\n",
        "n_classes = len(class_labels)\n",
        "print(f\"Classes: {class_labels}, Total: {n_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46d5bba4",
      "metadata": {
        "id": "46d5bba4"
      },
      "source": [
        "## Define Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119b77bd",
      "metadata": {
        "id": "119b77bd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "class SSDDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transforms=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transforms = transforms\n",
        "        self.image_files = sorted(os.listdir(image_dir))\n",
        "        self.label_files = sorted(os.listdir(label_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        # Load label\n",
        "        label_path = os.path.join(self.label_dir, self.label_files[idx])\n",
        "        with open(label_path, 'r') as f:\n",
        "            boxes = []\n",
        "            labels = []\n",
        "            for line in f:\n",
        "                data = list(map(float, line.strip().split()))\n",
        "                labels.append(int(data[0]))  # Class ID\n",
        "                x_center, y_center, width, height = data[1:]\n",
        "                x_min = x_center - width / 2\n",
        "                y_min = y_center - height / 2\n",
        "                x_max = x_center + width / 2\n",
        "                y_max = y_center + height / 2\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "\n",
        "        # Convert to tensors\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "        target = {'boxes': boxes, 'labels': labels}\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64193f7f",
      "metadata": {
        "id": "64193f7f"
      },
      "source": [
        "## Define Transformations and Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0802ac1c",
      "metadata": {
        "id": "0802ac1c"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((640, 640)),\n",
        "])\n",
        "\n",
        "dataset = SSDDataset(image_dir, label_dir, transforms=transform)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55e5ec65",
      "metadata": {
        "id": "55e5ec65"
      },
      "source": [
        "## Load Pretrained SSD MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b5e8757",
      "metadata": {
        "id": "5b5e8757"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
        "import torch\n",
        "\n",
        "# Load pre-trained model\n",
        "model = ssdlite320_mobilenet_v3_large(weights=\"DEFAULT\")\n",
        "\n",
        "# Update the model to the desired number of classes (e.g., 2 for background and fish)\n",
        "num_classes = n_classes + 1  # background + fish\n",
        "\n",
        "# Access the classification head\n",
        "classification_head = model.head.classification_head\n",
        "\n",
        "# Modify the final convolution layer in the last block (module_list[-1])\n",
        "# The last module in the `module_list` corresponds to the final classification layer\n",
        "final_conv_layer = classification_head.module_list[-1][1]\n",
        "\n",
        "# Replace the final conv layer with a new one that outputs `num_classes`\n",
        "final_conv_layer.out_channels = num_classes\n",
        "\n",
        "# Replace the last Conv2d layer with a new Conv2d that has the correct output channels\n",
        "classification_head.module_list[-1][1] = torch.nn.Conv2d(\n",
        "    in_channels=final_conv_layer.in_channels,\n",
        "    out_channels=num_classes,  # Number of classes\n",
        "    kernel_size=final_conv_layer.kernel_size,\n",
        "    stride=final_conv_layer.stride,\n",
        "    padding=final_conv_layer.padding\n",
        ")\n",
        "\n",
        "# Now, the model is updated with the correct number of output classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5284007",
      "metadata": {
        "id": "d5284007"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77263575",
      "metadata": {
        "id": "77263575"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import SGD\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, targets in dataloader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        total_loss += losses.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5972b0d1",
      "metadata": {
        "id": "5972b0d1"
      },
      "source": [
        "## Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7e2e9a",
      "metadata": {
        "id": "9a7e2e9a"
      },
      "outputs": [],
      "source": [
        "# Save trained model\n",
        "model_save_path = f'{dataset_root}/ssd_mobilenet.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50af905c",
      "metadata": {
        "id": "50af905c"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa3c892",
      "metadata": {
        "id": "6fa3c892"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_predictions(image, predictions):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "    for box, label in zip(predictions['boxes'], predictions['labels']):\n",
        "        x_min, y_min, x_max, y_max = box\n",
        "        plt.gca().add_patch(\n",
        "            plt.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min,\n",
        "                          fill=False, edgecolor='red', linewidth=2)\n",
        "        )\n",
        "        plt.text(x_min, y_min, class_labels[label], color='blue', fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "# Load an image for testing\n",
        "image, _ = dataset[0]\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model([image.to(device)])[0]\n",
        "\n",
        "visualize_predictions(image, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b56bfa6",
      "metadata": {
        "id": "1b56bfa6"
      },
      "source": [
        "## Issues\n",
        "\n",
        "If you have any issues or receive any errors, please go to the <a href = \"https://github.com/krupaltisgaonkar/pytorch-ssd\">Github Page</a> and file an issue."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}